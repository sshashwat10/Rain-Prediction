import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier
from sklearn.metrics import accuracy_score, confusion_matrix

# Load the data
file_path = "C:/Users/Shashwat/Downloads/FINAL INTERVIEW/sydney_rain prediction.xlsx"
data = pd.read_excel(file_path)

# Display the first few rows of the data
print(data.head())

# Data Preprocessing
data['Date'] = pd.to_datetime(data['Date'])
data.fillna(method='ffill', inplace=True)  # Forward fill missing values

# Extract features (X) and target variable (y)
X = data.drop(['Date', 'Location', 'RainTomorrow'], axis=1)
y = data['RainTomorrow']

# Convert categorical variables to numerical using one-hot encoding
X = pd.get_dummies(X)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train Decision Tree Classifier
dt_classifier = DecisionTreeClassifier(random_state=42)
dt_classifier.fit(X_train, y_train)
dt_predictions = dt_classifier.predict(X_test)

# Train Random Forest Classifier
rf_classifier = RandomForestClassifier(random_state=42)
rf_classifier.fit(X_train, y_train)
rf_predictions = rf_classifier.predict(X_test)

# Train Gradient Boosting Classifier
gb_classifier = GradientBoostingClassifier(random_state=42)
gb_classifier.fit(X_train, y_train)
gb_predictions = gb_classifier.predict(X_test)

# Train Bagging Classifier
bagging_classifier = BaggingClassifier(n_estimators=10, random_state=42)
bagging_classifier.fit(X_train, y_train)
bagging_predictions = bagging_classifier.predict(X_test)

# Evaluate models
conf_matrices = {
    "Decision Tree": confusion_matrix(y_test, dt_predictions),
    "Random Forest": confusion_matrix(y_test, rf_predictions),
    "Gradient Boosting": confusion_matrix(y_test, gb_predictions),
    "Bagging": confusion_matrix(y_test, bagging_predictions),
}

# Check the lengths of y_test and predictions
for model, predictions in zip(["Decision Tree", "Random Forest", "Gradient Boosting", "Bagging"],
                              [dt_predictions, rf_predictions, gb_predictions, bagging_predictions]):
    print(f"len(y_test): {len(y_test)}, len(predictions): {len(predictions)}")

# Compare the models
model_accuracies = {model: accuracy_score(y_test, predictions) for model, predictions in zip(conf_matrices, [dt_predictions, rf_predictions, gb_predictions, bagging_predictions])}

# Retrieve and print the confusion matrix of the best model
best_model = max(model_accuracies, key=model_accuracies.get)

# Print the results and confusion matrix of the best model
print(f"\nBest Model: {best_model}")
print(f"Accuracy of {best_model}: {model_accuracies[best_model]}")
print(f"Confusion Matrix of {best_model}:\n {conf_matrices[best_model]}")

